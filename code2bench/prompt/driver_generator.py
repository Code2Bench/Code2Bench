SELF_CONTAINED_DRIVER_GENERATION_PROMPT = """
## Task Description
You are an expert Python developer specializing in property-based testing with the `hypothesis` library and differential testing techniques. Your task is to generate a **complete and executable Python test driver** using `hypothesis` for a given Python function (`func0`, provided in the "Input" section). This driver will be used for differential testing to compare the behavior of `func0` (ground truth) against another function (implicitly `func1`, the LLM-generated code, but you don't need to know about `func1` explicitly in driver generation).

The generated driver must include all necessary components for a functional Hypothesis test:
1. **Import Statements**:
   - Start with importing `hypothesis` and `hypothesis.strategies as st`.
   - Import `func1` from the tested module.
2. **Givens Generation**:
   - Analyze the input function `func0`'s signature and **crucially, infer input types from type hints (if available) or argument names and function context**.
   - For each input argument of `func0`, generate a corresponding `hypothesis.strategies` code snippet to produce diverse and valid input values. Use appropriate strategies from `hypothesis.strategies` (e.g., `st.integers()`, `st.text()`, `st.lists()`, `st.recursive()`, etc.).
   - If the function handles complex or nested inputs (like lists of lists, dictionaries, etc.), consider using `st.recursive` to generate such structures effectively.
3. **Test Function Definition**:
   - Define a Python test function decorated with `@given(...)`.
   - Use the generated `hypothesis.strategies` as arguments to the `@given` decorator, mapping each strategy to the corresponding argument name of `func0`.
   - The test function should accept the same arguments as `func0`, as generated by `hypothesis`.
4. **Differential Testing Logic**:
   - Inside the test function:
     - Call the ground truth function `func0` with the generated input arguments and store the result as `expected_output`. **Assume `func0` is defined and accessible in the test environment.**
     - Call the function being tested (implicitly `func1`, which for driver generation purposes, you can also refer to as `func0` within the driver code for simplicity). Call it with the **same** generated input arguments and store the result as `actual_output`. **In differential testing, you will later replace this `func0` call with a call to the LLM-generated function (`func1`) in your actual test setup.**
5. **Assertions**:
   - **Core Differential Assertion**: Include the essential assertion: `assert expected_output == actual_output`(may vary for float comparation). This is the heart of differential testing, ensuring the outputs of `func0` and `func1` are identical for the same inputs. Provide a descriptive error message in the `assert` statement, including the input values, `expected_output`, and `actual_output` for debugging.
   - **May be different for deep comparison**: If the output is a nested data structure, you may need to use a deep comparison.
   - **Optional Property-based Assertions**: If applicable and you can infer properties of the output, add additional `assert` statements to check for basic properties of `actual_output`. For example, if you expect a list as output, assert `isinstance(actual_output, list)`. These are secondary to the core differential assertion but can add robustness.
6. **Complete and Executable Driver Code**:
   - Ensure the generated code is a **complete, self-contained, and executable Python script** that defines the Hypothesis test driver. It should be ready to run assuming `func0` (and later `func1`) are defined in the same environment.

## Input
The Python code for the ground truth function `func0` is provided below:
```python
{func_code}
## Output
Generate a JSON response containing a single key "Driver". The value of "Driver" should be a string containing the complete Python code for the Hypothesis test driver, including import statements, Givens, the test function with @given, differential testing logic, and assertions. The generated code must be ready to be executed.
```json
{
    "Driver": "# Complete Python code for Hypothesis Driver goes here, including imports, @given, test function, assertions, etc."
}

## Example
For a function like:
```python
def add(a: int, b: int) -> int:
    return a + b
```
The generated driver might look like:
```python
import hypothesis.strategies as st
from hypothesis import given
# Don't include func1 in the driver, just use it

def add(a: int, b: int) -> int:
    return a + b

@given(a=st.integers(), b=st.integers())
def test_add(a: int, b: int):
    expected_output = add(a, b)
    actual_output = func1(a, b)
    assert expected_output == actual_output, (
        f"Mismatch in outputs for inputs: {a}, {b}.\n"
        f"Expected: {expected_output}\n"
        f"Actual: {actual_output}"
    )
```

## Note
- Just use `func1` for the function being tested in the driver code, don't include func1 in the driver, just use it. But define func0 in the driver code
- Focus on Differential Testing: The primary goal is to compare the output of func0 with another function (implicitly func1). The driver should facilitate this comparison.
- Prioritize Type Hints for Givens: Use type hints in func0's signature to guide the generation of hypothesis.strategies. If type hints are missing, infer types based on argument names and common Python practices.
- Consider Complex Input Structures: If func0 handles nested data, use st.recursive or other appropriate strategies to generate complex inputs.
"""

SELF_CONTAINED_DRIVER_GENERATION_PROMPT_v0 = """
## Task Description

You are an expert Python developer specializing in property-based testing with the `hypothesis` library and differential testing techniques. Your task is to generate a **complete and executable Python test driver** using `hypothesis` for a given Python function (`func0`, provided in the "Input" section). This driver will be used for differential testing to compare the behavior of `func0` (ground truth) against another function (implicitly `func1`, the LLM-generated code, but you don't need to know about `func1` explicitly in driver generation).

The generated driver must include all necessary components for a functional Hypothesis test:
1. **Import Statements**:
   - Start with importing `hypothesis` and `hypothesis.strategies as st`.
   - Import `func1` from the tested module.
2. **Givens Generation**:
   - Analyze the input function `func0`'s signature and **crucially, infer input types from type hints (if available) or argument names and function context**.
   - For each input argument of `func0`, generate a corresponding `hypothesis.strategies` code snippet to produce diverse and valid input values. Use appropriate strategies from `hypothesis.strategies` (e.g., `st.integers()`, `st.text()`, `st.lists()`, `st.recursive()`, etc.).
   - If the function handles complex or nested inputs (like lists of lists, dictionaries, etc.), consider using `st.recursive` to generate such structures effectively.
3. **Test Function Definition**:
   - Define a Python test function decorated with `@given(...)`.
   - Use the generated `hypothesis.strategies` as arguments to the `@given` decorator, mapping each strategy to the corresponding argument name of `func0`.
   - The test function should accept the same arguments as `func0`, as generated by `hypothesis`.
4. **Differential Testing Logic**:
   - Inside the test function:
     - Call the ground truth function `func0` with the generated input arguments and store the result as `expected_output`. **Assume `func0` is defined and accessible in the test environment.**
     - Call the function being tested (implicitly `func1`, which for driver generation purposes, you can also refer to as `func0` within the driver code for simplicity). Call it with the **same** generated input arguments and store the result as `actual_output`. **In differential testing, you will later replace this `func0` call with a call to the LLM-generated function (`func1`) in your actual test setup.**
5. **Assertions**:
   - **Core Differential Assertion**: Include the essential assertion: `assert expected_output == actual_output`(may vary for float comparation). This is the heart of differential testing, ensuring the outputs of `func0` and `func1` are identical for the same inputs. Provide a descriptive error message in the `assert` statement, including the input values, `expected_output`, and `actual_output` for debugging.
   - **May be different for deep comparison**: If the output is a nested data structure, you may need to use a deep comparison.
   - **Optional Property-based Assertions**: If applicable and you can infer properties of the output, add additional `assert` statements to check for basic properties of `actual_output`. For example, if you expect a list as output, assert `isinstance(actual_output, list)`. These are secondary to the core differential assertion but can add robustness.
6. **Complete and Executable Driver Code**:
   - Ensure the generated code is a **complete, self-contained, and executable Python script** that defines the Hypothesis test driver. It should be ready to run assuming `func0` (and later `func1`) are defined in the same environment.

## Input
The Python code for the ground truth function `func0` is provided below:
```python
{func_code}
## Output
Generate a JSON response containing a single key "Driver". The value of "Driver" should be a string containing the complete Python code for the Hypothesis test driver, including import statements, Givens, the test function with @given, differential testing logic, and assertions. The generated code must be ready to be executed.
```json
{
    "Driver": "# Complete Python code for Hypothesis Driver goes here, including imports, @given, test function, assertions, etc."
}

## Example
For a function like:
```python
def add(a: int, b: int) -> int:
    return a + b
```
The generated driver might look like:
```python
import hypothesis.strategies as st
from hypothesis import given
# Don't include func1 in the driver, just use it

def add(a: int, b: int) -> int:
    return a + b

@given(a=st.integers(), b=st.integers())
def test_add(a: int, b: int):
    expected_output = add(a, b)
    actual_output = func1(a, b)
    assert expected_output == actual_output, (
        f"Mismatch in outputs for inputs: {a}, {b}.\n"
        f"Expected: {expected_output}\n"
        f"Actual: {actual_output}"
    )
```

## Note
- Just use `func1` for the function being tested in the driver code, don't include func1 in the driver, just use it. But define func0 in the driver code
- Focus on Differential Testing: The primary goal is to compare the output of func0 with another function (implicitly func1). The driver should facilitate this comparison.
- Prioritize Type Hints for Givens: Use type hints in func0's signature to guide the generation of hypothesis.strategies. If type hints are missing, infer types based on argument names and common Python practices.
- Consider Complex Input Structures: If func0 handles nested data, use st.recursive or other appropriate strategies to generate complex inputs.
"""

LEVEL_1_SELF_CONTAINED_DRIVER_GENERATION_PROMPT = """
## Task Description

You are an expert Python developer specializing in property-based testing with the `hypothesis` library and differential testing techniques. Your task is to generate a **complete and executable Python test driver** using `hypothesis` for a given Python function (`func0`, provided in the "Input" section, which calls a self-contained function `func_self_contained`). This driver will be used for differential testing to compare the behavior of `func0` (ground truth) against another function (implicitly `func1`, the LLM-generated code, but you don't need to know about `func1` explicitly in driver generation).

The generated driver must include all necessary components for a functional Hypothesis test:
1. **Import Statements**:
   - Start with importing `hypothesis` and `hypothesis.strategies as st`.
   - Import `func1` from the tested module.
2. **Givens Generation**:
   - Analyze the input function `func0`'s signature and **crucially, infer input types from type hints (if available) or argument names and function context**.
   - For each input argument of `func0`, generate a corresponding `hypothesis.strategies` code snippet to produce diverse and valid input values. Use appropriate strategies from `hypothesis.strategies` (e.g., `st.integers()`, `st.text()`, `st.lists()`, `st.recursive()`, etc.).
   - If the function handles complex or nested inputs (like lists of lists, dictionaries, etc.), consider using `st.recursive` to generate such structures effectively.
3. **Test Function Definition**:
   - Define a Python test function decorated with `@given(...)`.
   - Use the generated `hypothesis.strategies` as arguments to the `@given` decorator, mapping each strategy to the corresponding argument name of `func0`.
   - The test function should accept the same arguments as `func0`, as generated by `hypothesis`.
4. **Differential Testing Logic**:
   - Inside the test function:
     - Call the ground truth function `func0` with the generated input arguments and store the result as `expected_output`. **Assume `func0` is defined and accessible in the test environment.**
     - Call the function being tested (implicitly `func1`, which for driver generation purposes, you can also refer to as `func0` within the driver code for simplicity). Call it with the **same** generated input arguments and store the result as `actual_output`. **In differential testing, you will later replace this `func0` call with a call to the LLM-generated function (`func1`) in your actual test setup.**
5. **Assertions**:
   - **Core Differential Assertion**: Include the essential assertion: `assert expected_output == actual_output`(may vary for float comparation). This is the heart of differential testing, ensuring the outputs of `func0` and `func1` are identical for the same inputs. Provide a descriptive error message in the `assert` statement, including the input values, `expected_output`, and `actual_output` for debugging.
   - **May be different for deep comparison**: If the output is a nested data structure, you may need to use a deep comparison.
   - **Optional Property-based Assertions**: If applicable and you can infer properties of the output, add additional `assert` statements to check for basic properties of `actual_output`. For example, if you expect a list as output, assert `isinstance(actual_output, list)`. These are secondary to the core differential assertion but can add robustness.
6. **Complete and Executable Driver Code**:
   - Ensure the generated code is a **complete, self-contained, and executable Python script** that defines the Hypothesis test driver. It should be ready to run assuming `func0` (and later `func1`) are defined in the same environment.

## Input
The Python code for the ground truth function `func0` is provided below:
```python
{func_code}
## Output
Generate a JSON response containing a single key "Driver". The value of "Driver" should be a string containing the complete Python code for the Hypothesis test driver, including import statements, Givens, the test function with @given, differential testing logic, and assertions. The generated code must be ready to be executed.
```json
{
    "Driver": "# Complete Python code for Hypothesis Driver goes here, including imports, @given, test function, assertions, etc."
}

## Example
For a function like:
```python
# func0:
def add_and_multiply(a: int, b: int) -> int:
    add_result = add(a, b)
    return add_result * 2

# func_self_contained:
def add(a: int, b: int) -> int:
    return a + b
```
The generated driver might look like:
```python
import hypothesis.strategies as st
from hypothesis import given
# Don't include func1 in the driver, just use it

def add_and_multiply(a: int, b: int) -> int:
    add_result = add(a, b)
    return add_result * 2

def add(a: int, b: int) -> int:
    return a + b

@given(a=st.integers(), b=st.integers())
def test_add_and_multiply(a: int, b: int):
    expected_output = add_and_multiply(a, b)
    actual_output = func1(a, b)
    assert expected_output == actual_output, (
        f"Mismatch in outputs for inputs: {a}, {b}.\n"
        f"Expected: {expected_output}\n"
        f"Actual: {actual_output}"
    )
```

## Note
- Just use `func1` for the function being tested in the driver code, don't include func1 in the driver, just use it. But define func0 in the driver code
- Focus on Differential Testing: The primary goal is to compare the output of func0 with another function (implicitly func1). The driver should facilitate this comparison.
- Prioritize Type Hints for Givens: Use type hints in func0's signature to guide the generation of hypothesis.strategies. If type hints are missing, infer types based on argument names and common Python practices.
- Consider Complex Input Structures: If func0 handles nested data, use st.recursive or other appropriate strategies to generate complex inputs.
"""

WEAKLY_SELF_CONTAINED_DRIVER_GENERATION_PROMPT = """## Task Description
You are an expert Python developer specializing in property-based testing with the `hypothesis` library and differential testing techniques. Your task is to generate a **complete and executable Python test driver** using `hypothesis` for a given Python function (`func0`, provided in the "Input" section, which calls a lib function `lib_func`). This driver will be used for differential testing to compare the behavior of `func0` (ground truth) against another function (implicitly `func1`, the LLM-generated code, but you don't need to know about `func1` explicitly in driver generation).

The generated driver must include all necessary components for a functional Hypothesis test:
1. **Import Statements**:
   - Start with importing `hypothesis` and `hypothesis.strategies as st`.
   - Import `func1` from the tested module.
   - Import `lib_func` from the library module.
2. **Givens Generation**:
   - Analyze the input function `func0`'s signature and **crucially, infer input types from type hints (if available) or argument names and function context**.
   - For each input argument of `func0`, generate a corresponding `hypothesis.strategies` code snippet to produce diverse and valid input values. Use appropriate strategies from `hypothesis.strategies` (e.g., `st.integers()`, `st.text()`, `st.lists()`, `st.recursive()`, etc.).
   - If the function handles complex or nested inputs (like lists of lists, dictionaries, etc.), consider using `st.recursive` to generate such structures effectively.
3. **Test Function Definition**:
   - Define a Python test function decorated with `@given(...)`.
   - Use the generated `hypothesis.strategies` as arguments to the `@given` decorator, mapping each strategy to the corresponding argument name of `func0`.
   - The test function should accept the same arguments as `func0`, as generated by `hypothesis`.
4. **Differential Testing Logic**:
   - Inside the test function:
     - Call the ground truth function `func0` with the generated input arguments and store the result as `expected_output`. **Assume `func0` is defined and accessible in the test environment.**
     - Call the function being tested (implicitly `func1`, which for driver generation purposes, you can also refer to as `func0` within the driver code for simplicity). Call it with the **same** generated input arguments and store the result as `actual_output`. **In differential testing, you will later replace this `func0` call with a call to the LLM-generated function (`func1`) in your actual test setup.**
5. **Assertions**:
   - **Core Differential Assertion**: Include the essential assertion: `assert expected_output == actual_output`(may vary for float comparation). This is the heart of differential testing, ensuring the outputs of `func0` and `func1` are identical for the same inputs. Provide a descriptive error message in the `assert` statement, including the input values, `expected_output`, and `actual_output` for debugging.
   - **May be different for deep comparison**: If the output is a nested data structure, you may need to use a deep comparison.
   - **Optional Property-based Assertions**: If applicable and you can infer properties of the output, add additional `assert` statements to check for basic properties of `actual_output`. For example, if you expect a list as output, assert `isinstance(actual_output, list)`. These are secondary to the core differential assertion but can add robustness.
6. **Complete and Executable Driver Code**:
   - Ensure the generated code is a **complete, self-contained, and executable Python script** that defines the Hypothesis test driver. It should be ready to run assuming `func0` (and later `func1`) are defined in the same environment.

## Input
The Python code for the ground truth function `func0` is provided below:
```python
{func_code}
## Output
Generate a JSON response containing a single key "Driver". The value of "Driver" should be a string containing the complete Python code for the Hypothesis test driver, including import statements, Givens, the test function with @given, differential testing logic, and assertions. The generated code must be ready to be executed.
```json
{
    "Driver": "# Complete Python code for Hypothesis Driver goes here, including imports, @given, test function, assertions, etc."
}

## Example
For a function like:
```python
# func0:
def add(a: int, b: int) -> int:
    add_result = math.add(a, b)
    return add_result

# lib_func:
math.add
```
The generated driver might look like:
```python
import hypothesis.strategies as st
from hypothesis import given
import math
# Don't include func1 in the driver, just use it

def add(a: int, b: int) -> int:
    add_result = math.add(a, b)
    return add_result

@given(a=st.integers(), b=st.integers())
def test_add(a: int, b: int):
    expected_output = add(a, b)
    actual_output = func1(a, b)
    assert expected_output == actual_output, (
        f"Mismatch in outputs for inputs: {a}, {b}.\n"
        f"Expected: {expected_output}\n"
        f"Actual: {actual_output}"
    )
```

## Note
- Just use `func1` for the function being tested in the driver code, don't include func1 in the driver, just use it. But define func0 in the driver code
- Focus on Differential Testing: The primary goal is to compare the output of func0 with another function (implicitly func1). The driver should facilitate this comparison.
- Consider Complex Input Structures: If func0 handles nested data, use st.recursive or other appropriate strategies to generate complex inputs.
- Don't forget to add import statement for lib_func with nessesary typings if needed.
- Only return the driver code in the JSON response, no additional information is required.
"""

# WEAKLY_SELF_CONTAINED_DRIVER_GENERATION_PROMPT = """## Task Description
# You are an expert Python developer specializing in property-based testing with the `hypothesis` library and differential testing techniques. Your task is to generate a **complete and executable Python test driver** using `hypothesis` for a given Python function (`func0`, provided in the "Input" section, which calls a lib function `lib_func`). This driver will be used for differential testing to compare the behavior of `func0` (ground truth) against another function (implicitly `func1`, the LLM-generated code, but you don't need to know about `func1` explicitly in driver generation).

# The generated driver must include all necessary components for a functional Hypothesis test:
# 1. **Import Statements**:
#    - Start with importing `hypothesis` and `hypothesis.strategies as st`.
#    - Import `func1` from the tested module.
#    - Import `lib_func` from the library module.
# 2. **Givens Generation**:
#    - Analyze the input function `func0`'s signature and **crucially, infer input types from type hints (if available) or argument names and function context**.
#    - For each input argument of `func0`, generate a corresponding `hypothesis.strategies` code snippet to produce diverse and valid input values. Use appropriate strategies from `hypothesis.strategies` (e.g., `st.integers()`, `st.text()`, `st.lists()`, `st.recursive()`, etc.).
#    - If the function handles complex or nested inputs (like lists of lists, dictionaries, etc.), consider using `st.recursive` to generate such structures effectively.
# 3. **Test Function Definition**:
#    - Define a Python test function decorated with `@given(...)`.
#    - Use the generated `hypothesis.strategies` as arguments to the `@given` decorator, mapping each strategy to the corresponding argument name of `func0`.
#    - The test function should accept the same arguments as `func0`, as generated by `hypothesis`.
# 4. **Differential Testing Logic**:
#    - Inside the test function:
#      - Call the ground truth function `func0` with the generated input arguments and store the result as `expected_output`. **Assume `func0` is defined and accessible in the test environment.**
#      - Call the function being tested (implicitly `func1`, which for driver generation purposes, you can also refer to as `func0` within the driver code for simplicity). Call it with the **same** generated input arguments and store the result as `actual_output`. **In differential testing, you will later replace this `func0` call with a call to the LLM-generated function (`func1`) in your actual test setup.**
# 5. **Assertions**:
#    - **Core Differential Assertion**: Include the essential assertion: `assert expected_output == actual_output`(may vary for float comparation). This is the heart of differential testing, ensuring the outputs of `func0` and `func1` are identical for the same inputs. Provide a descriptive error message in the `assert` statement, including the input values, `expected_output`, and `actual_output` for debugging.
#    - **May be different for deep comparison**: If the output is a nested data structure, you may need to use a deep comparison.
#    - **Optional Property-based Assertions**: If applicable and you can infer properties of the output, add additional `assert` statements to check for basic properties of `actual_output`. For example, if you expect a list as output, assert `isinstance(actual_output, list)`. These are secondary to the core differential assertion but can add robustness.
# 6. **Complete and Executable Driver Code**:
#    - Ensure the generated code is a **complete, self-contained, and executable Python script** that defines the Hypothesis test driver. It should be ready to run assuming `func0` (and later `func1`) are defined in the same environment.

# ## Input
# The Python code for the ground truth function `func0` is provided below:
# ```python
# {func_code}
# ## Output
# Generate a JSON response containing a single key "Driver". The value of "Driver" should be a string containing the complete Python code for the Hypothesis test driver, including import statements, Givens, the test function with @given, differential testing logic, and assertions. The generated code must be ready to be executed.
# ```json
# {
#     "Driver": "# Complete Python code for Hypothesis Driver goes here, including imports, @given, test function, assertions, etc."
# }

# ## Example
# For a function like:
# ```python
# # func0:
# def add(a: int, b: int) -> int:
#     add_result = math.add(a, b)
#     return add_result

# # lib_func:
# math.add
# ```
# The generated driver might look like:
# ```python
# import hypothesis.strategies as st
# from hypothesis import given
# import math
# # Don't include func1 in the driver, just use it

# def add(a: int, b: int) -> int:
#     add_result = math.add(a, b)
#     return add_result

# @given(a=st.integers(), b=st.integers())
# def test_add(a: int, b: int):
#     expected_output = add(a, b)
#     actual_output = func1(a, b)
#     assert expected_output == actual_output, (
#         f"Mismatch in outputs for inputs: {a}, {b}.\n"
#         f"Expected: {expected_output}\n"
#         f"Actual: {actual_output}"
#     )
# ```

# ## Note
# - Just use `func1` for the function being tested in the driver code, don't include func1 in the driver, just use it. But define func0 in the driver code
# - Focus on Differential Testing: The primary goal is to compare the output of func0 with another function (implicitly func1). The driver should facilitate this comparison.
# - Prioritize Type Hints for Givens: Use type hints in func0's signature to guide the generation of hypothesis.strategies. If type hints are missing, infer types based on argument names and common Python practices. And don't forget to import the library function used in func0 including types.
# - Consider Complex Input Structures: If func0 handles nested data, use st.recursive or other appropriate strategies to generate complex inputs.
# - Only return the driver code in the JSON response, no additional information is required.
# """